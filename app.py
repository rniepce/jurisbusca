import streamlit as st
import os
from dotenv import load_dotenv
from backend import process_uploaded_file, run_gemini_orchestration, process_templates, generate_style_report
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
# from prompts import LEGAL_ASSISTANT_PROMPT # Obsoleto com multi-agentes

# Configura√ß√£o da P√°gina
st.set_page_config(
    page_title="Assistente Rafa - Intelig√™ncia Jur√≠dica",
    page_icon="‚öñÔ∏è",
    layout="wide"
)

# Carrega vari√°veis de ambiente
load_dotenv()

# --- CSS Personalizado ---
st.markdown("""
<style>
    .reportview-container {
        background: #f0f2f6;
    }
    .main-header {
        font-size: 2.5rem;
        color: #2c3e50;
        font-weight: 700;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #34495e;
    }
    .chat-container {
        border-radius: 10px;
        padding: 20px;
        background-color: white;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
</style>
""", unsafe_allow_html=True)

# --- SIDEBAR: Configura√ß√µes e Upload ---
with st.sidebar:
    st.title("üéõÔ∏è Controle de Testes")
    
    # Bot√£o de Reset (Nova Conversa)
    if st.button("üóëÔ∏è Nova An√°lise / Limpar Tudo"):
        # Limpa chaves espec√≠ficas do estado
        keys_to_reset = ["messages", "process_text", "retriever", "current_file_name"]
        for key in keys_to_reset:
            if key in st.session_state:
                del st.session_state[key]
        
        # For√ßa recria√ß√£o do uploader mudando a key
        if "uploader_key" not in st.session_state:
            st.session_state.uploader_key = 0
        st.session_state.uploader_key += 1
        st.rerun()

    # Inicializa key do uploader
    if "uploader_key" not in st.session_state:
        st.session_state.uploader_key = 0

    st.header("1. Upload do Processo")
    
    # API KEY logo no in√≠cio para liberar fun√ß√µes
    google_api_key = st.text_input("Google API Key (Para Gemini):", type="password")
    
    uploaded_file = st.file_uploader(
        "Carregue o arquivo (PDF, DOCX, TXT)", 
        type=["pdf", "docx", "txt"],
        help="O arquivo ser√° processado (OCR se necess√°rio) e vetorizado para an√°lise.",
        key=f"uploader_{st.session_state.uploader_key}"
    )
    
    st.markdown("---")
    
    st.header("üìÇ Banco de Modelos (RAG)")
    template_files = st.file_uploader(
        "Suba seus despacho/senten√ßas para o Gemini usar como estilo:",
        type=["pdf", "docx", "txt"],
        accept_multiple_files=True
    )
    
    if template_files:
        st.success(f"‚úÖ {len(template_files)} modelos recebidos!")
        
        if st.button("üé® Gerar Relat√≥rio de Estilo (Preview)"):
            if not google_api_key:
                st.error("Insira a API Key do Google primeiro.")
            else:
                with st.spinner("Lendo modelos e criando perfil estil√≠stico (Gemini Flash)..."):
                    try:
                        # Processa apenas para pegar os textos
                        _, docs = process_templates(template_files, google_api_key)
                        if docs:
                            report = generate_style_report(docs, google_api_key)
                            # Salva no session state para exibir na tela principal
                            st.session_state.style_report_preview = report
                        else:
                            st.warning("N√£o consegui extrair texto dos arquivos.")
                    except Exception as e:
                        st.error(f"Erro ao gerar estilo: {e}")

    st.markdown("---")

    # google_api_key ja foi pedido acima
    st.markdown("---")
    
    st.info("‚ú® **Modo Google Gemini Pro:**\nEste ambiente roda exclusivamente com a IA mais avan√ßada do Google para tarefas jur√≠dicas.")

# --- L√≥gica Principal ---

st.markdown('<div class="main-header">ü§ñ Assistente Rafa</div>', unsafe_allow_html=True)
st.write("Ferramenta para teste e valida√ß√£o de LLMs finetunados em tarefas de an√°lise jur√≠dica.")

# Exibe Preview do Estilo se houver
if "style_report_preview" in st.session_state and st.session_state.style_report_preview:
    st.info("üé® **Perfil de Estilo Identificado (Dossi√™ do Magistrado):**")
    st.markdown(st.session_state.style_report_preview)
    if st.button("Fechar Preview do Estilo"):
        del st.session_state.style_report_preview
        st.rerun()
    st.markdown("---")

# Inicializa estado da sess√£o
if "messages" not in st.session_state:
    st.session_state.messages = []
if "process_text" not in st.session_state:
    st.session_state.process_text = ""
if "retriever" not in st.session_state:
    st.session_state.retriever = None
if "current_file_name" not in st.session_state:
    st.session_state.current_file_name = None

# Processamento do Arquivo
if uploaded_file:
    # Se mudou o arquivo, limpa o estado e reprocessa
    if st.session_state.current_file_name != uploaded_file.name:
        st.session_state.messages = []
        st.session_state.process_text = ""
        st.session_state.retriever = None
        st.session_state.current_file_name = uploaded_file.name
        
        with st.spinner(f"Processando {uploaded_file.name}... (OCR + Vetoriza√ß√£o)"):
            # Reseta o buffer para o in√≠cio
            uploaded_file.seek(0)
            
            # Chama backend para OCR e Vetoriza√ß√£o
            text, retriever = process_uploaded_file(uploaded_file, uploaded_file.name, api_key=google_api_key)
            
            if text.startswith("Erro") or text.startswith("Formato"):
                st.error(text)
            else:
                st.session_state.process_text = text
                st.session_state.retriever = retriever
                st.success(f"Processamento conclu√≠do! {len(text)} caracteres extra√≠dos. Vetoriza√ß√£o ativa.")
                
    # Mostra preview (opcional)
    with st.expander("üìÑ Ver conte√∫do textual extra√≠do (OCR)"):
        st.text_area("Conte√∫do bruto", st.session_state.process_text, height=200)

    # Bot√£o de A√ß√£o Principal
    col1, col2 = st.columns([1, 4])
    with col1:
        analyze_btn = st.button("üöÄ Rodar An√°lise Jur√≠dica", type="primary")
    
    if analyze_btn:
        # from backend import run_orchestration, run_gemini_orchestration # J√° importado no topo
        
        if not st.session_state.process_text:
            st.error("O texto do arquivo est√° vazio.")
        else:
            # Limpa chat anterior para nova an√°lise
            st.session_state.messages = []
            
            # L√≥gica de Orquestra√ß√£o Multi-Agente
            
            # Container de Status Expans√≠vel (Novo no Streamlit)
            status_box = st.status("ü§ñ Iniciando Orquestra√ß√£o de Agentes...", expanded=True)
            
            def update_status(msg):
                status_box.write(msg)
                
            try:
                # Pipeline exclusiva do Gemini (Railway Deploy)
                results = run_gemini_orchestration(
                    text=st.session_state.process_text,
                    api_key=google_api_key,
                    status_callback=update_status,
                    template_files=template_files
                )
                
                status_box.update(label="‚úÖ An√°lise e Auditoria Conclu√≠das!", state="complete", expanded=False)
                
                # 1. PARSEAMENTO DO OUTPUT (Separar Diagn√≥stico vs Minuta)
                full_text = results.get("steps", {}).get("integral", results["final_report"])
                
                # Tenta separar a Minuta (geralmente ap√≥s "## 3. MINUTA" ou "## MINUTA")
                import re
                parts = re.split(r'##\s*3\.\s*MINUTA|##\s*MINUTA', full_text, flags=re.IGNORECASE)
                
                if len(parts) > 1:
                    diagnostic_text = parts[0]
                    minuta_text = parts[1].strip()
                    # Remove poss√≠vel rodap√© de fim de arquivo do prompt ou assinatura extra
                    minuta_text = re.split(r'---', minuta_text)[0].strip()
                else:
                    # Fallback: se n√£o achar a divis√£o, mostra tudo
                    diagnostic_text = "Diagn√≥stico integral incorporado ao texto."
                    minuta_text = full_text

                # 2. √ÇNCORA (MINUTA FINAL)
                st.subheader("üìù Minuta da Decis√£o (Texto Puro)")
                # 'language=None' tira as cores de markdown e 'st.code' garante o bot√£o de copiar 
                st.code(minuta_text, language=None)
                
                # 3. BOT√ïES DE ACESSO (DI√ÅLOGOS/POPOVERS)
                st.markdown("---")
                st.write("üîé **Painel de Controle:**")
                
                c1, c2, c3, c4 = st.columns(4)
                
                with c1:
                    with st.popover("üß† Ver Diagn√≥stico e Fundamenta√ß√£o"):
                        st.markdown("### üß† Racioc√≠nio (Chain-of-Thought)")
                        st.markdown(diagnostic_text)
                
                with c2:
                    dashboard_text = results.get("auditor_dashboard", "")
                    if dashboard_text:
                        with st.popover("üõ°Ô∏è Ver Auditoria (Compliance)"):
                            st.markdown("### üõ°Ô∏è Relat√≥rio do Auditor")
                            st.markdown(dashboard_text)
                
                with c3:
                    style_report = results.get("style_report", "")
                    if style_report:
                        with st.popover("üé® Ver An√°lise de Estilo"):
                            st.markdown("### üé® Dossi√™ de Estilo Identificado")
                            st.markdown(style_report)

                with c4:
                    with st.popover("üïµÔ∏è Detalhes T√©cnicos"):
                        st.markdown("### ‚öôÔ∏è Logs da Orquestra√ß√£o")
                        st.json(results.get("steps", {}))
                
                # Salva no hist√≥rico (apenas a minuta para ser √∫til)
                st.session_state.messages.append({"role": "user", "content": f"Analise o processo {uploaded_file.name} (Modo Multi-Agente)"})
                st.session_state.messages.append({"role": "assistant", "content": minuta_text})
                
            except Exception as e:
                import traceback
                st.error(f"Erro na execu√ß√£o da orquestra√ß√£o: {e}")
                st.text(traceback.format_exc())

else:
    st.info("üëà Fa√ßa o upload de um processo na barra lateral para come√ßar.")

# --- √Årea de Chat (P√≥s An√°lise com RAG) ---
if st.session_state.messages and st.session_state.retriever:
    st.markdown("---")
    st.subheader("üí¨ Chat Interativo (com Busca Vetorial)")
    
    # Exibe hist√≥rico
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
            
    # Input
    if prompt := st.chat_input("Fa√ßa perguntas sobre o caso..."):
        with st.chat_message("user"):
            st.markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        with st.spinner("Pesquisando nos autos e gerando resposta..."):
            try:
                from langchain_google_genai import ChatGoogleGenerativeAI
                
                if not google_api_key:
                    st.error("Insira a Google API Key na barra lateral.")
                else:
                    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", google_api_key=google_api_key, temperature=0.3)
                    
                    # 1. RAG Retrieval: Busca trechos relevantes para a pergunta
                    retrieved_docs = st.session_state.retriever.invoke(prompt)
                    context_str = "\n\n".join([doc.page_content for doc in retrieved_docs])
                    
                    # 2. Montagem do Hist√≥rico (simplificado para Gemini)
                    chat_history = [
                        SystemMessage(content="Voc√™ √© um assistente jur√≠dico especializado. Responda de forma precisa, citando os documentos quando relevante."),
                    ]
                    
                    for msg in st.session_state.messages[:-1]:
                        if msg["role"] == "user":
                            chat_history.append(HumanMessage(content=msg["content"]))
                        else:
                            chat_history.append(AIMessage(content=msg["content"]))
                    
                    # 3. Adiciona a Pergunta Atual com Contexto Enriquecido (RAG)
                    rag_message_content = f"""
                    Informa√ß√µes Relevantes encontradas nos autos atrav√©s de busca vetorial:
                    {context_str}
                    
                    Pergunta do Usu√°rio:
                    {prompt}
                    """
                    chat_history.append(HumanMessage(content=rag_message_content))
                    
                    # 4. Invoke LLM
                    response = llm.invoke(chat_history)
                    
                    with st.chat_message("assistant"):
                        st.markdown(response.content)
                    
                    st.session_state.messages.append({"role": "assistant", "content": response.content})
                
            except Exception as e:
                import traceback
                st.error(f"Erro: {e}")
                st.expander("Detalhes do erro").text(traceback.format_exc())
