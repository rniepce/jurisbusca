import streamlit as st
import os
from dotenv import load_dotenv
import json
import re
import traceback
import pandas as pd
import plotly.express as px
from backend import process_uploaded_file, run_standard_orchestration, run_ensemble_orchestration, process_templates, generate_style_report, generate_batch_xray, process_batch_parallel, load_persistent_rag, HAS_GEMINI, GEMINI_IMPORT_ERROR
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
# from prompts import LEGAL_ASSISTANT_PROMPT # Obsoleto com multi-agentes

# Configura√ß√£o da P√°gina
st.set_page_config(
    page_title="Assistente Rafa - Intelig√™ncia Jur√≠dica",
    page_icon="‚öñÔ∏è",
    layout="wide"
)

# Carrega vari√°veis de ambiente
load_dotenv()


# ==============================================================================
# 0. ROTEAMENTO (ROUTER) - PARA ABAS NOVAS (PRIORIDADE ALTA)
# ==============================================================================
query_params = st.query_params
if "report_id" in query_params:
    report_id = query_params["report_id"]
    try:
        # Load from persistent storage
        file_path = f"data/reports/{report_id}.json"
        
        if not os.path.exists(file_path):
             st.error(f"Relat√≥rio n√£o encontrado: {file_path}")
             st.stop()
             
        with open(file_path, "r") as f:
            data = json.load(f)
            
        # Defensive fix for 'list' vs 'dict'
        if isinstance(data, list):
            if len(data) > 0 and isinstance(data[0], dict):
                data = data[0]
            else:
                 st.error(f"Formato de relat√≥rio inv√°lido (Lista): {str(data)[:100]}")
                 st.stop()
        
        # --- VIEW: PROCESSO INDIVIDUAL (NOVA ABA) ---
        st.title(f"‚öñÔ∏è Processo: {data.get('filename', 'Detalhes')}")
        
        # Recupera dados
        steps_data = data.get("steps", {})
        if isinstance(steps_data, dict):
            integral_text = steps_data.get("integral")
        else:
            integral_text = None
            
        full_text = integral_text if integral_text else data.get("final_report", "")
        
        if isinstance(full_text, list):
            full_text = "\n".join([str(x) for x in full_text])
        elif not isinstance(full_text, str):
            full_text = str(full_text if full_text is not None else "")
            
        # Tenta separar a Minuta (m√∫ltiplos padr√µes poss√≠veis) - SYNC COM LOGICA PRINCIPAL
        patterns = [
            r'##\s*3\.\s*MINUTA',
            r'##\s*MINUTA',
            r'\*\*DO\s+ATO\s+JUDICIAL\*\*',
            r'DO\s+ATO\s+JUDICIAL',
            r'\*\*SENTEN√áA\*\*',
            r'\*\*DECIS√ÉO\*\*',
            r'##\s*SENTEN√áA',
            r'##\s*DECIS√ÉO'
        ]
        
        minuta_text = None
        diagnostic_text = None
        
        for pattern in patterns:
            parts = re.split(pattern, full_text, flags=re.IGNORECASE)
            if len(parts) > 1:
                diagnostic_text = parts[0].strip()
                minuta_text = parts[1].strip()
                break
        
        if not minuta_text:
            diagnostic_text = "Diagn√≥stico integral."
            minuta_text = full_text

        # --- NOVA L√ìGICA V3/V2: REASONING EXPL√çCITO ---
        # Se o backend mandou "diagnostic_reasoning" (V2/V3), usa ele.
        if data.get("diagnostic_reasoning"):
            diagnostic_text = data.get("diagnostic_reasoning")
        
        # V1 Fallback sem√¢ntico (Tenta extrair do JSON se for o caso)
        if not diagnostic_text or diagnostic_text == "Diagn√≥stico integral.":
             if isinstance(full_text, str) and '"fundamentacao_logica":' in full_text:
                 try:
                     import re
                     match = re.search(r'"fundamentacao_logica":\s*"(.*?)"', full_text, re.DOTALL)
                     if match:
                         diagnostic_text = match.group(1).replace("\\n", "\n")
                 except:
                     pass

        # --- CORRE√á√ÉO DE FORMATA√á√ÉO E LIMPEZA FINAL ---
        if minuta_text and isinstance(minuta_text, str):
            minuta_text = minuta_text.replace("\\n", "\n")
            if "'extras':" in minuta_text:
                    minuta_text = minuta_text.split("'extras':")[0].strip().rstrip(",").strip()
            elif '"extras":' in minuta_text:
                    minuta_text = minuta_text.split('"extras":')[0].strip().rstrip(",").strip()
            minuta_text = minuta_text.strip().strip("'").strip('"')

        # Renderiza Decis√£o
        st.subheader("üìù Minuta da Decis√£o")
        st.text_area("Copie o texto abaixo:", value=minuta_text, height=600, label_visibility="collapsed")
        
        st.markdown("---")
        st.write("üîé **Painel de Controle:**")
        
        with st.expander("üõ†Ô∏è Debug do Texto Original (Se algo estiver cortado)"):
            st.text(f"Tamanho do Texto Original: {len(full_text) if full_text else 0}")
            st.code(str(full_text)[:500])
            
        c1, c2, c3, c4 = st.columns(4)
        with c1:
            with st.popover("üß† Diagn√≥stico", use_container_width=True):
                st.markdown(diagnostic_text)
        with c2:
            if data.get("auditor_dashboard"):
                with st.popover("üõ°Ô∏è Auditoria", use_container_width=True):
                    st.markdown(data["auditor_dashboard"])
        with c3:
            if data.get("style_report"):
                with st.popover("üé® Estilo", use_container_width=True):
                    st.markdown(data["style_report"])
        with c4:
             with st.popover("‚öôÔ∏è Logs", use_container_width=True):
                st.json(data.get("steps", {}))
        
        st.markdown("---")
        st.info("üí¨ Modo de Visualiza√ß√£o R√°pida (Sess√£o Simplificada)")
        
    except Exception as e:
        st.error(f"Erro ao carregar relat√≥rio: {e}")
    
    st.stop() # PARA A EXECU√á√ÉO AQUI PARA ESTA ABA


# ==============================================================================
# 0. ROTEAMENTO (ROUTER) - PARA ABAS NOVAS (PRIORIDADE ALTA)
# ==============================================================================
query_params = st.query_params
if "report_id" in query_params:
    report_id = query_params["report_id"]
    try:
        # Load from persistent storage
        file_path = f"data/reports/{report_id}.json"
        
        if not os.path.exists(file_path):
             st.error(f"Relat√≥rio n√£o encontrado: {file_path}")
             st.stop()
             
        with open(file_path, "r") as f:
            data = json.load(f)
            
        # Defensive fix for 'list' vs 'dict'
        if isinstance(data, list):
            if len(data) > 0 and isinstance(data[0], dict):
                data = data[0]
            else:
                 st.error(f"Formato de relat√≥rio inv√°lido (Lista): {str(data)[:100]}")
                 st.stop()
        
        # --- VIEW: PROCESSO INDIVIDUAL (NOVA ABA) ---
        st.title(f"‚öñÔ∏è Processo: {data.get('filename', 'Detalhes')}")
        
        # Recupera dados
        steps_data = data.get("steps", {})
        if isinstance(steps_data, dict):
            integral_text = steps_data.get("integral")
        else:
            integral_text = None
            
        full_text = integral_text if integral_text else data.get("final_report", "")
        
        if isinstance(full_text, list):
            full_text = "\n".join([str(x) for x in full_text])
        elif not isinstance(full_text, str):
            full_text = str(full_text if full_text is not None else "")
            
        # Tenta separar a Minuta (m√∫ltiplos padr√µes poss√≠veis) - SYNC COM LOGICA PRINCIPAL
        patterns = [
            r'##\s*3\.\s*MINUTA',
            r'##\s*MINUTA',
            r'\*\*DO\s+ATO\s+JUDICIAL\*\*',
            r'DO\s+ATO\s+JUDICIAL',
            r'\*\*SENTEN√áA\*\*',
            r'\*\*DECIS√ÉO\*\*',
            r'##\s*SENTEN√áA',
            r'##\s*DECIS√ÉO'
        ]
        
        minuta_text = None
        diagnostic_text = None
        
        for pattern in patterns:
            parts = re.split(pattern, full_text, flags=re.IGNORECASE)
            if len(parts) > 1:
                diagnostic_text = parts[0].strip()
                minuta_text = parts[1].strip()
                break
        
        if not minuta_text:
            diagnostic_text = "Diagn√≥stico integral."
            minuta_text = full_text

        # --- NOVA L√ìGICA V3/V2 (NOVA ABA) ---
        if data.get("diagnostic_reasoning"):
            diagnostic_text = data.get("diagnostic_reasoning")

        # V1 Fallback sem√¢ntico
        if not diagnostic_text or diagnostic_text == "Diagn√≥stico integral.":
             if isinstance(full_text, str) and '"fundamentacao_logica":' in full_text:
                 try:
                     import re
                     match = re.search(r'"fundamentacao_logica":\s*"(.*?)"', full_text, re.DOTALL)
                     if match:
                         diagnostic_text = match.group(1).replace("\\n", "\n")
                 except:
                     pass

        # --- CORRE√á√ÉO DE FORMATA√á√ÉO E LIMPEZA FINAL ---
        if minuta_text and isinstance(minuta_text, str):
            minuta_text = minuta_text.replace("\\n", "\n")
            if "'extras':" in minuta_text:
                    minuta_text = minuta_text.split("'extras':")[0].strip().rstrip(",").strip()
            elif '"extras":' in minuta_text:
                    minuta_text = minuta_text.split('"extras":')[0].strip().rstrip(",").strip()
            minuta_text = minuta_text.strip().strip("'").strip('"')

        # Renderiza Decis√£o
        st.subheader("üìù Minuta da Decis√£o")
        st.text_area("Copie o texto abaixo:", value=minuta_text, height=600, label_visibility="collapsed")
        
        st.markdown("---")
        st.write("üîé **Painel de Controle:**")
        
        with st.expander("üõ†Ô∏è Debug do Texto Original (Se algo estiver cortado)"):
            st.text(f"Tamanho do Texto Original: {len(full_text) if full_text else 0}")
            st.code(str(full_text)[:500])
            
        c1, c2, c3, c4 = st.columns(4)
        with c1:
            with st.popover("üß† Diagn√≥stico", use_container_width=True):
                st.markdown(diagnostic_text)
        with c2:
            if data.get("auditor_dashboard"):
                with st.popover("üõ°Ô∏è Auditoria", use_container_width=True):
                    st.markdown(data["auditor_dashboard"])
        with c3:
            if data.get("style_report"):
                with st.popover("üé® Estilo", use_container_width=True):
                    st.markdown(data["style_report"])
        with c4:
             with st.popover("‚öôÔ∏è Logs", use_container_width=True):
                st.json(data.get("steps", {}))
        
        st.markdown("---")
        st.info("üí¨ Modo de Visualiza√ß√£o R√°pida (Sess√£o Simplificada)")
        
    except Exception as e:
        st.error(f"Erro ao carregar relat√≥rio: {e}")
    
    st.stop() # PARA A EXECU√á√ÉO AQUI PARA ESTA ABA

# --- CSS Personalizado (Design Moderno) ---
st.markdown("""
<style>
    /* Paleta de Cores Moderna */
    :root {
        --primary-color: #4F46E5; /* Indigo */
        --secondary-color: #10B981; /* Emerald */
        --background-dark: #1E1B4B;
        --text-primary: #1F2937;
        --text-secondary: #6B7280;
        --surface: #FFFFFF;
        --surface-hover: #F3F4F6;
    }
    
    /* Header Principal */
    .main-header {
        font-size: 2.8rem;
        background: linear-gradient(135deg, var(--primary-color), #7C3AED);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-weight: 800;
        letter-spacing: -0.5px;
        margin-bottom: 0.5rem;
    }
    
    .subtitle {
        font-size: 1.1rem;
        color: var(--text-secondary);
        margin-bottom: 2rem;
    }
    
    /* Sidebar */
    [data-testid="stSidebar"] {
        background: linear-gradient(180deg, #F8FAFC 0%, #EEF2FF 100%);
    }
    
    [data-testid="stSidebar"] h1 {
        font-size: 1.4rem !important;
        color: var(--primary-color) !important;
    }
    
    /* Bot√µes */
    .stButton > button {
        background: linear-gradient(135deg, var(--primary-color), #7C3AED);
        color: white;
        border: none;
        border-radius: 12px;
        padding: 0.7rem 1.5rem;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 14px rgba(79, 70, 229, 0.3);
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(79, 70, 229, 0.4);
    }
    
    /* Cards e Containers */
    .stExpander {
        border: 1px solid #E5E7EB;
        border-radius: 12px;
        overflow: hidden;
    }
    
    /* Status Box */
    [data-testid="stStatusWidget"] {
        border-radius: 12px;
        border: 1px solid #E5E7EB;
    }
    
    /* Code Block (Minuta) */
    .stCodeBlock {
        border-radius: 12px !important;
        border: 2px solid var(--primary-color) !important;
    }
    
    /* Popovers */
    [data-testid="stPopover"] > div {
        border-radius: 16px;
        box-shadow: 0 25px 50px -12px rgba(0, 0, 0, 0.25);
    }
    
    /* Input Fields */
    .stTextInput > div > div > input {
        border-radius: 10px;
        border: 2px solid #E5E7EB;
        transition: border-color 0.2s ease;
    }
    
    .stTextInput > div > div > input:focus {
        border-color: var(--primary-color);
        box-shadow: 0 0 0 3px rgba(79, 70, 229, 0.1);
    }
    
    /* File Uploader */
    [data-testid="stFileUploader"] {
        border: 2px dashed #E5E7EB;
        border-radius: 12px;
        padding: 1rem;
        transition: border-color 0.2s ease;
    }
    
    [data-testid="stFileUploader"]:hover {
        border-color: var(--primary-color);
    }
    
    /* Success/Info Messages */
    .stSuccess, .stInfo {
        border-radius: 10px;
    }
    
    /* Chat Messages */
    [data-testid="stChatMessage"] {
        border-radius: 16px;
        padding: 1rem;
    }
</style>
""", unsafe_allow_html=True)

# --- SIDEBAR: Configura√ß√µes e Upload ---
with st.sidebar:
    st.title("üéõÔ∏è Controle de Testes")
    
    # Bot√£o de Reset (Nova Conversa)
    if st.button("üóëÔ∏è Nova An√°lise (Manter Modelos)"):
        # Limpa chaves espec√≠ficas do estado, MAS PRESERVA OS MODELOS
        keys_to_reset = ["messages", "process_text", "retriever", "current_file_name", "style_report_preview"]
        for key in keys_to_reset:
            if key in st.session_state:
                del st.session_state[key]
        
        # For√ßa recria√ß√£o APENAS do uploader principal
        if "uploader_key" not in st.session_state:
            st.session_state.uploader_key = 0
        st.session_state.uploader_key += 1
        st.rerun()

    # Inicializa key do uploader principal
    if "uploader_key" not in st.session_state:
        st.session_state.uploader_key = 0

    # API KEY logo no in√≠cio para liberar fun√ß√µes
    if "google_api_key" not in st.session_state:
        st.session_state.google_api_key = ""

    # Se a chave N√ÉO estiver definida, mostra input + bot√£o
    if not st.session_state.google_api_key:
        with st.container(border=True):
            st.markdown("### üîë Acesso")
            with st.form("login_form"):
                key_input = st.text_input("Cole sua Google API Key:", type="password", key="input_key_temp")
                submitted = st.form_submit_button("üîì Validar Acesso", type="primary", use_container_width=True)
            
            if submitted:
                if key_input.startswith("AIza"):
                    st.session_state.google_api_key = key_input
                    # Tenta carregar RAG persistente ao logar
                    retriever = load_persistent_rag(key_input)
                    if retriever:
                        st.session_state.retriever = retriever
                        st.toast("Banco de Modelos (RAG) Carregado!", icon="üìö")
                    st.toast("Chave Validada! Acesso Liberado.", icon="üéâ")
                    st.rerun()
                else:
                    st.error("Chave inv√°lida. Deve come√ßar com 'AIza'.")
        
    else:
        # Tenta carregar RAG se ainda n√£o tiver (reload de p√°gina)
        if st.session_state.get("retriever") is None and st.session_state.google_api_key:
             retriever = load_persistent_rag(st.session_state.google_api_key)
             if retriever:
                 st.session_state.retriever = retriever
        # Se J√Å tem chave, mostra status discreto com op√ß√£o de sair
        cols = st.columns([1.8, 1])
        cols[0].success("üîë Google Conectado", icon="‚úÖ")
        if cols[1].button("Sair", type="secondary", use_container_width=True, help="Trocar chave de acesso"):
            st.session_state.google_api_key = ""
            st.rerun()
            
        st.markdown("---")
        
        # SELETOR DE MODO (V1 vs V2 vs V3)
        mode_option = st.radio(
            "Modo de Opera√ß√£o:",
            ["V1: Standard (Multi-Model)", "V2: Linha de Montagem (Ensemble)", "V3: Agente Aut√¥nomo (SOTA)"],
            index=0,
            help="V1: R√°pido (1 LLM).\nV2: Potente (Gemini -> DeepSeek -> Claude).\nV3: Aut√¥nomo (Ferramentas + Python)."
        )
        
        if "V1" in mode_option:
            st.session_state.app_mode = "v1"
        elif "V2" in mode_option:
            st.session_state.app_mode = "v2"
        else:
            st.session_state.app_mode = "v3"
        
        # CONFIGURA√á√ÉO V1 (MULTI-MODELO)
        if st.session_state.app_mode == "v1":
             with st.expander("üõ†Ô∏è Configura√ß√£o do Motor (V1)", expanded=True):
                 st.caption("Escolha a intelig√™ncia por tr√°s do Analista Principal e do Analista de Estilo.")
                 
                 # Defini√ß√£o dos Modelos e Provedores
                 model_options = {
                     "Gemini 3.0 Pro": {"provider": "google", "model": "gemini-3-pro-preview"},
                     "Gemini Flash (R√°pido)": {"provider": "google", "model": "gemini-3-flash-preview"},
                     "DeepSeek R1 (L√≥gica Extrema)": {"provider": "deepseek", "model": "deepseek-reasoner"}, # Via DeepSeek API (OpenAI compat)
                     "GPT-5.1 Preview (Simulado/GPT-4o)": {"provider": "openai", "model": "gpt-4o"},
                     "Claude 4.5 Sonnet": {"provider": "anthropic", "model": "claude-sonnet-4-5-20250929"}
                 }
                 
                 # Seletores
                 sel_main = st.selectbox("üß† Modelo Principal (M√©rito/Minuta)", list(model_options.keys()), index=0)
                 sel_style = st.selectbox("üé® Modelo de Estilo (Personalidade)", list(model_options.keys()), index=1)
                 
                 # Captura as configs escolhidas
                 main_config = model_options[sel_main]
                 style_config = model_options[sel_style]
                 
                 # INPUT DE CHAVES DIN√ÇMICO
                 st.divider()
                 st.caption("Chaves de Acesso necess√°rias para os modelos escolhidos:")
                 
                 needed_providers = set([main_config['provider'], style_config['provider']])
                 
                 # Google (J√° temos a session_state.google_api_key validada l√° em cima)
                 main_config['key'] = st.session_state.google_api_key
                 style_config['key'] = st.session_state.google_api_key
                 
                 # OpenAI
                 if 'openai' in needed_providers:
                     if "openai_key_v1" not in st.session_state: st.session_state.openai_key_v1 = ""
                     k_val = st.text_input("OpenAI API Key", value=st.session_state.openai_key_v1, type="password", key="v1_oai_key")
                     st.session_state.openai_key_v1 = k_val
                     
                     if main_config['provider'] == 'openai': main_config['key'] = k_val
                     if style_config['provider'] == 'openai': style_config['key'] = k_val
                 
                 # DeepSeek
                 if 'deepseek' in needed_providers:
                     if "deepseek_key_v1" not in st.session_state: st.session_state.deepseek_key_v1 = ""
                     k_ds = st.text_input("DeepSeek API Key", value=st.session_state.deepseek_key_v1, type="password", key="v1_ds_key")
                     st.session_state.deepseek_key_v1 = k_ds
                     
                     if main_config['provider'] == 'deepseek': main_config['key'] = k_ds
                     if style_config['provider'] == 'deepseek': style_config['key'] = k_ds
                     
                 # Anthropic
                 if 'anthropic' in needed_providers:
                     if "anthropic_key_v1" not in st.session_state: st.session_state.anthropic_key_v1 = ""
                     k_ant = st.text_input("Anthropic API Key", value=st.session_state.anthropic_key_v1, type="password", key="v1_ant_key")
                     st.session_state.anthropic_key_v1 = k_ant
                     
                     if main_config['provider'] == 'anthropic': main_config['key'] = k_ant
                     if style_config['provider'] == 'anthropic': style_config['key'] = k_ant
                 
                 # Salva no Session State para uso nos bot√µes de a√ß√£o
                 st.session_state.v1_main_config = main_config
                 st.session_state.v1_style_config = style_config

        # CONFIGURA√á√ÉO V2/V3 (Chaves Extras)
        if st.session_state.app_mode in ["v2", "v3"]:
            with st.expander("‚öôÔ∏è Configurar Banca Digital (V2/V3)", expanded=True):
                st.caption("Insira as chaves para ativar a equipe completa.")
                
                # OpenAI (Input com valida√ß√£o visual)
                if "openai_key" not in st.session_state: st.session_state.openai_key = ""
                o_key = st.text_input("OpenAI API Key (Auditor GPT-4o)", value=st.session_state.openai_key, type="password", key="input_openai")
                if o_key: 
                    st.session_state.openai_key = o_key
                    if o_key.startswith("sk-"): st.success("V√°lida!", icon="‚úÖ")
                    else: st.warning("Formato estranho...")

                # Anthropic
                if "anthropic_key" not in st.session_state: st.session_state.anthropic_key = ""
                a_key = st.text_input("Anthropic API Key (Redator Claude)", value=st.session_state.anthropic_key, type="password", key="input_anthropic")
                if a_key:
                    st.session_state.anthropic_key = a_key
                    if a_key.startswith("sk-ant"): st.success("V√°lida!", icon="‚úÖ")
                    else: st.warning("Formato estranho...")

                # DeepSeek
                if "deepseek_key" not in st.session_state: st.session_state.deepseek_key = ""
                d_key = st.text_input("DeepSeek API Key (Juiz Reasoning)", value=st.session_state.deepseek_key, type="password", key="input_deepseek")
                if d_key:
                    st.session_state.deepseek_key = d_key
                    if d_key.startswith("sk-"): st.success("V√°lida!", icon="‚úÖ")
                    else: st.warning("Formato estranho...")
                
                if not (st.session_state.openai_key and st.session_state.anthropic_key and st.session_state.deepseek_key):
                    st.warning("‚ö†Ô∏è Preencha todas as chaves para usar o Modo V2/V3 (Ensemble/Agente).")

        # GEST√ÉO DE PRECEDENTES (VINCULA√á√ÉO)
        with st.expander("üìö Base Vicunlante (Knowledge)", expanded=False):
            st.caption("Arquivos de consulta obrigat√≥ria do Prompt V4.5")
            
            # Arquivo A: Sobrestamentos
            f_sobre = st.file_uploader("Arquivo A: Sobrestamentos", type=["txt"], key="upload_sobre")
            if f_sobre:
                with open("data/knowledge_base/sobrestamentos.txt", "wb") as f: f.write(f_sobre.getbuffer())
                # st.toast("Sobrestamentos Atualizados!", icon="üíæ") # SILENT MODE
            
            # Arquivo B: S√∫mulas
            f_sumula = st.file_uploader("Arquivo B: S√∫mulas", type=["txt"], key="upload_sumula")
            if f_sumula:
                 with open("data/knowledge_base/sumulas.txt", "wb") as f: f.write(f_sumula.getbuffer())
                 # st.toast("S√∫mulas Atualizadas!", icon="üíæ") # SILENT MODE

            # Arquivo C: Qualificados
            f_qualif = st.file_uploader("Arquivo C: Qualificados", type=["txt"], key="upload_qualif")
            if f_qualif:
                 with open("data/knowledge_base/qualificados.txt", "wb") as f: f.write(f_qualif.getbuffer())
                 # st.toast("Qualificados Atualizados!", icon="üíæ") # SILENT MODE
        
    google_api_key = st.session_state.google_api_key
    
    if not google_api_key:
        st.info("üëà Por favor, insira sua Google API Key na barra lateral para liberar o sistema.")
        st.stop()

    st.header("1. Banco de Modelos (RAG)")
    template_files = st.file_uploader(
        "Suba seus despacho/senten√ßas para o Gemini usar como estilo:",
        type=["pdf", "docx", "txt"],
        accept_multiple_files=True,
        key="rag_templates_uploader" # Key fixa para n√£o resetar
    )
    
    if template_files:
        st.success(f"‚úÖ {len(template_files)} modelos recebidos!")
        
        if st.button("üé® Gerar Relat√≥rio de Estilo (Preview)"):
             if not google_api_key:
                 st.error("Insira a Google API Key na barra lateral.")
             else:
                with st.spinner("Lendo modelos e criando perfil estil√≠stico..."):
                    try:
                        # Processa apenas para pegar os textos
                        _, docs = process_templates(template_files, google_api_key)
                        if docs:
                            report = generate_style_report(docs, google_api_key)
                            # Salva no session state para exibir na tela principal
                            st.session_state.style_report_preview = report
                        else:
                            if not HAS_GEMINI:
                                st.error(f"‚ö†Ô∏è ERRO CR√çTICO: Bibliotecas do Google n√£o instaladas (langchain-google-genai). Imposs√≠vel extrair texto ou gerar embeddings.\nDetalhe do erro: {GEMINI_IMPORT_ERROR}")
                            else:
                                st.warning("N√£o consegui extrair texto dos arquivos. Verifique se est√£o corrompidos ou vazios.")
                    except Exception as e:
                        st.error(f"Erro ao gerar estilo: {e}")
    
    st.markdown("---")

    st.header("2. Upload do Processo(s)")
    
    uploaded_files = st.file_uploader(
        "Carregue os arquivos (PDF, DOCX, TXT)", 
        type=["pdf", "docx", "txt"],
        help="Para an√°lise individual ou em lote (Raio-X).",
        accept_multiple_files=True, # Agora aceita m√∫ltiplos
        key=f"uploader_{st.session_state.uploader_key}"
    )

    st.markdown("---")
    
    st.info("‚ú® **Modo Google Gemini Pro:**\nEste ambiente roda exclusivamente com a IA mais avan√ßada do Google para tarefas jur√≠dicas.")

# --- L√≥gica Principal ---

st.markdown('<div class="main-header">ü§ñ Assistente Rafa</div>', unsafe_allow_html=True)
st.markdown('<p class="subtitle">Intelig√™ncia Artificial para An√°lise Jur√≠dica Profunda</p>', unsafe_allow_html=True)

# Exibe Preview do Estilo se houver
if "style_report_preview" in st.session_state and st.session_state.style_report_preview:
    st.info("üé® **Perfil de Estilo Identificado (Dossi√™ do Magistrado):**")
    st.markdown(st.session_state.style_report_preview)
    if st.button("Fechar Preview do Estilo"):
        del st.session_state.style_report_preview
        st.rerun()
    st.markdown("---")

# ==============================================================================
# L√ìGICA PRINCIPAL (DASHBOARD / GABINETE)
# ==============================================================================

# Inicializa estado da sess√£o
if "messages" not in st.session_state:
    st.session_state.messages = []
if "process_text" not in st.session_state:
    st.session_state.process_text = ""
if "retriever" not in st.session_state:
    st.session_state.retriever = None
if "current_file_name" not in st.session_state:
    st.session_state.current_file_name = None
if "batch_results" not in st.session_state:
    st.session_state.batch_results = []
if "xray_report" not in st.session_state:
    st.session_state.xray_report = None

# Processamento do Arquivo
if uploaded_files:
    st.markdown("---")
    
    # Seletor de Modo (Autom√°tico com Override)
    default_index = 1 if len(uploaded_files) > 1 else 0
    mode = st.radio(
        "Modo de Opera√ß√£o:",
        ["üéØ An√°lise Profunda (Individual)", "üìä Raio-X de Carteira (Gabinete)"],
        index=default_index,
        horizontal=True,
        key="operation_mode"
    )
    
    # 1. MODO GABINETE / LOTE (Batch Processing)
    if mode == "üìä Raio-X de Carteira (Gabinete)":
        st.info(f"‚ö° **Modo Gabinete Ativo:** {len(uploaded_files)} arquivos selecionados para triagem.")
        
        col_xray, col_batch = st.columns(2) # Create columns for buttons

        # Bot√£o para Gerar Raio-X
        with col_xray:
            if st.button("‚ö° Gerar Raio-X da Carteira", type="primary"):
                if not google_api_key:
                    st.error("Insira a Google API Key na barra lateral.")
                else:
                    with st.spinner("Analisando carteira e gerando Dashboard (Isso pode levar alguns segundos)..."):
                        # generate_batch_xray returns (report_dict, text_cache_dict)
                        report, text_cache = generate_batch_xray(uploaded_files, google_api_key, template_files=template_files)
                        st.session_state.xray_report = report
                        st.session_state.file_text_cache = text_cache

        # Bot√£o para Processar Gabinete (Paralelo)
        with col_batch:
            if st.button("‚ö° An√°lise em Lote", type="secondary"): # Changed to secondary to differentiate
                if not google_api_key:
                    st.error("Insira a Google API Key na barra lateral.")
                else:
                    with st.spinner(f"Processando {len(uploaded_files)} casos em paralelo (Isso pode levar um tempo)..."):
                        # Processa em Paralelo e Salva JSONs
                        
                        # V2 Keys
                        keys_dict = {
                            "google": google_api_key,
                            "openai": st.session_state.get("openai_key"),
                            "anthropic": st.session_state.get("anthropic_key"),
                            "deepseek": st.session_state.get("deepseek_key")
                        }
                        
                        # V1 Configs (Inject if enabled)
                        if st.session_state.get("app_mode") == "v1":
                            keys_dict['v1_main_config'] = st.session_state.get('v1_main_config')
                            keys_dict['v1_style_config'] = st.session_state.get('v1_style_config')
                        results = process_batch_parallel(
                            uploaded_files, 
                            google_api_key, 
                            template_files=template_files,
                            mode=st.session_state.get("app_mode", "v1"),
                            keys=keys_dict
                        )
                        st.session_state.batch_results = results
        
        # Exibe Raio-X se houver
        if st.session_state.xray_report:
            report_data = st.session_state.xray_report
            
            if "error" in report_data:
                st.error(f"Erro ao gerar Raio-X: {report_data['error']}")
                with st.expander("Ver RAW"):
                    st.text(report_data.get("raw_content", ""))
            else:
                st.markdown("### üìä Raio-X da Carteira (Interativo)")
                
                # 1. Gr√°fico de Pizza (Plotly)
                try:
                    clusters = report_data.get("clusters", [])
                    if clusters:
                        df_clusters = pd.DataFrame(clusters)
                        fig = px.pie(df_clusters, names='nome', values='quantidade', title='Distribui√ß√£o por Temas')
                        st.plotly_chart(fig, use_container_width=True)
                except ImportError:
                    st.warning("‚ö†Ô∏è Instale 'plotly' e 'pandas' para ver os gr√°ficos.")
                except Exception as e:
                    st.error(f"Erro no gr√°fico: {e}")
                
                # 2. Lista de Clusters com A√ß√£o
                st.markdown("### üß© Grupos Identificados")
                for cluster in report_data.get("clusters", []):
                    with st.expander(f"üìÅ {cluster['nome']} ({cluster['quantidade']} processos)"):
                        st.markdown(f"**Descri√ß√£o:** {cluster['descricao_fato']}")
                        st.markdown(f"**Sugest√£o:** {cluster['sugestao_minuta']}")
                        st.markdown(f"**Arquivos:** {', '.join(cluster['arquivos'])}")
                        
                        # Bot√£o de A√ß√£o Espec√≠fica para o Cluster
                        if st.button(f"‚ö° Processar Grupo '{cluster['nome']}'", key=f"btn_{cluster['id']}"):
                            # Filtra os arquivos
                            target_filenames = cluster['arquivos']
                            subset_files = [f for f in uploaded_files if f.name in target_filenames]
                            
                            if not subset_files:
                                st.warning("Nenhum arquivo correspondente encontrado no upload atual (verifique os nomes).")
                            else:
                                if not google_api_key:
                                    st.error("Insira a Google API Key.")
                                else:
                                    progress_bar = st.progress(0)
                                    status_text = st.empty()
                                    
                                    def update_progress(current, total, filename):
                                        ratio = current / total
                                        progress_bar.progress(ratio)
                                        status_text.text(f"Processando {current}/{total}: {filename}...")
                                        
                                    try:
                                        # Chama processamento com callback
                                        keys_dict = {
                                            "google": google_api_key,
                                            "openai": st.session_state.get("openai_key"),
                                            "anthropic": st.session_state.get("anthropic_key"),
                                            "deepseek": st.session_state.get("deepseek_key")
                                        }
                                        
                                        # V1 Configs (Inject if enabled)
                                        if st.session_state.get("app_mode") == "v1":
                                            keys_dict['v1_main_config'] = st.session_state.get('v1_main_config')
                                            keys_dict['v1_style_config'] = st.session_state.get('v1_style_config')
                                        results = process_batch_parallel(
                                            subset_files, 
                                            google_api_key, 
                                            template_files=template_files, 
                                            text_cache_dict=st.session_state.file_text_cache,
                                            progress_callback=update_progress,
                                            mode=st.session_state.get("app_mode", "v1"),
                                            keys=keys_dict
                                        )
                                    except Exception as e:
                                        st.error(f"Erro no processamento em lote: {e}")
                                        import traceback
                                        st.text(traceback.format_exc())
                                        results = []
                                        
                                    status_text.empty()
                                    progress_bar.empty()
                                    
                                    # Adiciona aos resultados existentes
                                    existing_ids = {r.get('filename') for r in st.session_state.batch_results}
                                    added_count = 0
                                    
                                    # Ensure directory exists
                                    os.makedirs("data/reports", exist_ok=True)
                                    
                                    for new_res in results:
                                        if new_res.get('filename') not in existing_ids:
                                            # Save to disk for persistence
                                            rid = new_res.get('report_id')
                                            if rid:
                                                with open(f"data/reports/{rid}.json", "w") as f:
                                                    json.dump(new_res, f)
                                            
                                            st.session_state.batch_results.append(new_res)
                                            added_count += 1
                                    
                                    if added_count > 0:
                                        st.success(f"‚úÖ {added_count} novos processos analisados!")
                                    else:
                                        st.info("Nenhum processo novo adicionado (todos j√° processados).")

            st.markdown("---")

        # Exibe Resultados como Links (Grid)
        if st.session_state.batch_results:
            st.markdown("### üóÇÔ∏è Processos Analisados (Clique para abrir)")
            
            # Grid de 4 colunas para bot√µes compactos
            cols = st.columns(4)
            for i, res in enumerate(st.session_state.batch_results):
                with cols[i % 4]:
                    if "error" in res:
                        st.error(f"‚ùå {res['filename']}")
                        st.caption(res['error'])
                    else:
                        # Substituindo link_button por button + callback para preservar Session State
                        # Substituindo por HTML Link para garantir Nova Aba (target="_blank")
                        
                        # LAZY SAVE / SELF-HEALING: Garante que o arquivo existe antes de gerar o link
                        # Isso corrige o erro de "Relat√≥rio n√£o encontrado" para itens processados antes da persistence.
                        rid = res.get('report_id')
                        if rid:
                            fpath = f"data/reports/{rid}.json"
                            if not os.path.exists(fpath):
                                os.makedirs("data/reports", exist_ok=True)
                                with open(fpath, "w") as f:
                                    json.dump(res, f)

                        btn_html = f"""
                        <a href="?report_id={res['report_id']}" target="_blank" style="text-decoration:none;">
                            <div style="
                                border: none;
                                border-radius: 12px;
                                padding: 12px;
                                text-align: center;
                                background: linear-gradient(135deg, #4F46E5, #7C3AED);
                                color: white;
                                font-weight: 600;
                                box-shadow: 0 4px 14px rgba(79, 70, 229, 0.3);
                                transition: transform 0.2s, box-shadow 0.2s;
                            " onmouseover="this.style.transform='translateY(-2px)'; this.style.boxShadow='0 6px 20px rgba(79, 70, 229, 0.4)'" onmouseout="this.style.transform='translateY(0)'; this.style.boxShadow='0 4px 14px rgba(79, 70, 229, 0.3)'">
                                üìÑ <br> {res['filename'][:15]}...
                            </div>
                        </a>
                        """
                        st.markdown(btn_html, unsafe_allow_html=True)


    # 2. MODO INDIVIDUAL (Single File)
    else:
        # Se houver m√∫ltiplos arquivos, permite escolher qual analisar em profundidade
        if len(uploaded_files) > 1:
            uploaded_file = st.selectbox(
                "Selecione o processo para an√°lise detalhada:", 
                uploaded_files, 
                format_func=lambda x: x.name
            )
        else:
            uploaded_file = uploaded_files[0] # Pega o √∫nico arquivo
        
        # Se mudou o arquivo, limpa o estado e reprocessa
        if st.session_state.current_file_name != uploaded_file.name:
            st.session_state.messages = []
            st.session_state.process_text = ""
            st.session_state.retriever = None
            st.session_state.current_file_name = uploaded_file.name
            st.session_state.xray_report = None # Limpa X-RAY anterior se houver
            
            with st.spinner(f"Processando {uploaded_file.name}... (OCR + Vetoriza√ß√£o)"):
                # Reseta o buffer para o in√≠cio
                uploaded_file.seek(0)
                
                # Chama backend para OCR e Vetoriza√ß√£o
                text, retriever = process_uploaded_file(uploaded_file, uploaded_file.name, api_key=google_api_key)
                
                if text.startswith("Erro") or text.startswith("Formato"):
                    st.error(text)
                else:
                    st.session_state.process_text = text
                    st.session_state.retriever = retriever
                    st.success(f"Processamento conclu√≠do! {len(text)} caracteres extra√≠dos. Vetoriza√ß√£o ativa.")
                    
        # Mostra preview (opcional)
        with st.expander("üìÑ Ver conte√∫do textual extra√≠do (OCR)"):
            st.text_area("Conte√∫do bruto", st.session_state.process_text, height=200)

        # Bot√£o de A√ß√£o Principal
        col1, col2 = st.columns([1, 4])
        with col1:
            analyze_btn = st.button("üöÄ Rodar An√°lise Jur√≠dica", type="primary")
        
        if analyze_btn:
            # from backend import run_orchestration, run_gemini_orchestration # J√° importado no topo
            
            if not st.session_state.process_text:
                st.error("O texto do arquivo est√° vazio.")
            else:
                # Limpa chat anterior para nova an√°lise
                st.session_state.messages = []
                
                # L√≥gica de Orquestra√ß√£o Multi-Agente
                
                # Container de Status Expans√≠vel (Novo no Streamlit)
                status_box = st.status("ü§ñ Iniciando Orquestra√ß√£o de Agentes...", expanded=True)
                
                def update_status(msg):
                    status_box.write(msg)
                    
                try:
                    # Pipeline de Execu√ß√£o (V1 / V2 / V3)
                    
                    if st.session_state.app_mode == "v3":
                        # V3: AGENTE AUT√îNOMO (Agentic RLM)
                        # Nota: Placeholder enquanto V3 n√£o est√° 100% implementado
                        from backend import run_hybrid_orchestration
                        keys = {
                            "openai": st.session_state.openai_key,
                            "anthropic": st.session_state.anthropic_key,
                            "deepseek": st.session_state.deepseek_key,
                            "google": google_api_key
                        }
                        if run_hybrid_orchestration:
                            results = run_hybrid_orchestration(st.session_state.process_text, keys)
                            
                            # Type guard: V3/LangGraph sometimes returns list instead of dict
                            if isinstance(results, list):
                                results = {"final_report": "\n".join([str(x) for x in results]), "logs": []}
                            elif not isinstance(results, dict):
                                results = {"final_report": str(results), "logs": []}
                            
                            # Adapta√ß√£o de output do agente
                            if "final_output" in results: results["final_report"] = results["final_output"]
                            if "audit_report" in results: results["auditor_dashboard"] = results["audit_report"]
                            if "logs" in results: results["steps"] = results["logs"]
                        else:
                             st.error("Engine V3 n√£o encontrada.")
                             st.stop()
                             
                    elif st.session_state.app_mode == "v2":
                        # V2: LINHA DE MONTAGEM (ENSEMBLE)
                        # Requer keys carregadas
                        keys = {
                            "openai": st.session_state.openai_key,
                            "anthropic": st.session_state.anthropic_key,
                            "deepseek": st.session_state.deepseek_key,
                            "google": google_api_key
                        }
                        results = run_ensemble_orchestration(
                            text=st.session_state.process_text,
                            keys=keys,
                            status_callback=update_status,
                            template_files=template_files
                        )
                        
                    else:
                        # V1: STANDARD (SIMPLIFICADO)
                        main_conf = st.session_state.get('v1_main_config', {'provider': 'google', 'model': 'gemini-3-pro-preview', 'key': google_api_key})
                        style_conf = st.session_state.get('v1_style_config', {'provider': 'google', 'model': 'gemini-3-flash-preview', 'key': google_api_key})
                        
                        results = run_standard_orchestration(
                            text=st.session_state.process_text,
                            main_llm_config=main_conf,
                            style_llm_config=style_conf,
                            status_callback=update_status,
                            template_files=template_files,
                            google_key=google_api_key
                        )
                    
                    status_box.update(label="‚úÖ An√°lise e Auditoria Conclu√≠das!", state="complete", expanded=False)
                    
                    # 1. PARSEAMENTO DO OUTPUT (Separar Diagn√≥stico vs Minuta)
                    # Type guard: Ensure results is always a dict
                    print(f"DEBUG: results type = {type(results)}")  # Debug log
                    if not isinstance(results, dict):
                        if isinstance(results, list):
                            results = {"final_report": "\n".join([str(x) for x in results]), "steps": {}}
                        else:
                            results = {"final_report": str(results) if results else "", "steps": {}}
                        print(f"DEBUG: results converted to dict")
                    
                    # === PARSEAMENTO ROBUSTO (V1/V2/V3) ===
                    
                    minuta_text = ""
                    diagnostic_text = ""
                    
                    # CASO 1: V2 ou V3 (J√° estruturado no dicion√°rio)
                    if st.session_state.app_mode in ["v2", "v3"]:
                         print(f"DEBUG: Modo {st.session_state.app_mode} - Usando campos diretos.")
                         minuta_text = results.get("final_report", "")
                         
                         # Diagn√≥stico vem dos steps/logs
                         steps = results.get("steps", {})
                         diagnostic_parts = []
                         if "fatos" in steps: diagnostic_parts.append(f"**Fatos (Gemini):**\n{steps['fatos'][:500]}...")
                         if "analise_material" in steps: diagnostic_parts.append(f"**Racioc√≠nio (DeepSeek):**\n{steps['analise_material']}")
                         if "verdict_outline" in steps: diagnostic_parts.append(f"**Esbo√ßo (DeepSeek):**\n{steps['verdict_outline']}")
                         
                         if diagnostic_parts:
                             diagnostic_text = "\n\n".join(diagnostic_parts)
                         else:
                             diagnostic_text = "Sem diagn√≥stico detalhado nos logs."

                    # CASO 2: V1 (Pode ser JSON ou Markdown Raw)
                    else:
                        print(f"DEBUG: Modo V1 - Tentando Parse JSON ou Regex.")
                        raw_output = results.get("final_report", "")
                        
                        # Tenta Parse JSON (Prompt V3 Core)
                        try:
                            # Limpeza de markdown json wrapper
                            cleaned_json = raw_output.replace("```json", "").replace("```", "").strip()
                            data_v1 = json.loads(cleaned_json)
                            
                            if isinstance(data_v1, dict):
                                minuta_text = data_v1.get("minuta_final", "")
                                diag = data_v1.get("diagnostico", {})
                                mirror = data_v1.get("compliance_espelho", {})
                                fund = data_v1.get("fundamentacao_logica", "")
                                
                                # Formata Texto de Diagn√≥stico
                                diagnostic_text = f"**Diagn√≥stico Estruturado:**\n{json.dumps(diag, indent=2, ensure_ascii=False)}"
                                if mirror:
                                     diagnostic_text += f"\n\n**Compliance Espelho:**\n{json.dumps(mirror, indent=2, ensure_ascii=False)}"
                                if fund:
                                     diagnostic_text += f"\n\n**Fundamenta√ß√£o L√≥gica:**\n{fund}"
                                     
                                print("DEBUG: V1 JSON Parse Sucesso")
                            else:
                                raise ValueError("JSON n√£o √© dict")
                                
                        except Exception as e:
                            print(f"DEBUG: V1 JSON Parse Falhou ({e}). Tentando Regex Legacy.")
                            # Fallback: Regex Splitting (Legacy Prompt)
                            full_text = raw_output
                            
                            patterns = [
                                r'##\s*3\.\s*MINUTA', r'##\s*MINUTA',
                                r'\*\*DO\s+ATO\s+JUDICIAL\*\*', r'DO\s+ATO\s+JUDICIAL',
                                r'\*\*SENTEN√áA\*\*', r'\*\*DECIS√ÉO\*\*',
                                r'##\s*SENTEN√áA', r'##\s*DECIS√ÉO'
                            ]
                            
                            minuta_text = None
                            for pattern in patterns:
                                parts = re.split(pattern, full_text, flags=re.IGNORECASE)
                                if len(parts) > 1:
                                    diagnostic_text = parts[0].strip()
                                    minuta_text = parts[1].strip()
                                    break
                            
                            if not minuta_text:
                                diagnostic_text = "Diagn√≥stico integral (N√£o foi poss√≠vel separar minuta)."
                                minuta_text = full_text

                    # --- CORRE√á√ÉO DE FORMATA√á√ÉO E LIMPEZA FINAL ---
                    if minuta_text and isinstance(minuta_text, str):
                        # 1. Converte quebras de linha escapadas para reais
                        minuta_text = minuta_text.replace("\\n", "\n")
                        
                        # 2. Remove artefatos de dicion√°rio Python/JSON vazando no final
                        # Solu√ß√£o "Nuclear": Corta tudo a partir de 'extras': {'signature'
                        # Isso previne qualquer varia√ß√£o de regex complexo
                        if "'extras':" in minuta_text:
                             minuta_text = minuta_text.split("'extras':")[0].strip().rstrip(",").strip()
                        elif '"extras":' in minuta_text:
                             minuta_text = minuta_text.split('"extras":')[0].strip().rstrip(",").strip()
                        
                        # 3. Remove aspas de tupla se sobrarem no in√≠cio/fim
                        minuta_text = minuta_text.strip().strip("'").strip('"')

                    # 3. BOT√ïES DE ACESSO (DI√ÅLOGOS/POPOVERS)
                    st.markdown("---")
                    st.write("üîé **Painel de Controle:**")
                    
                    # Layout: 3 colunas iguais para alinhar os bot√µes
                    c1, c2, c3 = st.columns(3)
                    
                    with c1:
                        with st.popover("üß† Ver Diagn√≥stico", use_container_width=True): 
                            st.markdown("### üß† Racioc√≠nio (Chain-of-Thought)")
                            # Fix escaped newlines for proper display
                            display_text = diagnostic_text.replace("\\n", "\n") if isinstance(diagnostic_text, str) else str(diagnostic_text)
                            st.markdown(display_text)
                    
                    with c2:
                        dashboard_text = results.get("auditor_dashboard", "")
                        if dashboard_text:
                            with st.popover("üõ°Ô∏è Ver Auditoria", use_container_width=True):
                                st.markdown("### üõ°Ô∏è Relat√≥rio do Auditor")
                                # Fix escaped newlines
                                display_audit = dashboard_text.replace("\\n", "\n") if isinstance(dashboard_text, str) else str(dashboard_text)
                                st.markdown(display_audit)
                    
                    with c3:
                        style_report = results.get("style_report", "")
                        if style_report:
                            with st.popover("üé® Ver Estilo", use_container_width=True):
                                st.markdown("### üé® Dossi√™ de Estilo Identificado")
                                # Fix escaped newlines
                                display_style = style_report.replace("\\n", "\n") if isinstance(style_report, str) else str(style_report)
                                st.markdown(display_style)

                    # Removido Coluna 4 (Debug) como solicitado
                    
                    # Salva no hist√≥rico (apenas a minuta para ser √∫til)
                    st.session_state.messages.append({"role": "user", "content": f"Analise o processo {uploaded_file.name} (Modo Multi-Agente)"})
                    st.session_state.messages.append({"role": "assistant", "content": minuta_text})
                    
                except Exception as e:
                    st.error(f"Erro na execu√ß√£o da orquestra√ß√£o: {e}")
                    st.text(traceback.format_exc())

else:
    st.info("üëà Fa√ßa o upload de um processo (ou v√°rios para Raio-X) na barra lateral para come√ßar.")

# --- √Årea de Chat (P√≥s An√°lise com RAG) ---
if st.session_state.messages and st.session_state.retriever:
    st.markdown("---")
    st.subheader("üí¨ Chat Interativo (com Busca Vetorial)")
    
    # Exibe hist√≥rico
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
            
    # Input
    if prompt := st.chat_input("Fa√ßa perguntas sobre o caso..."):
        with st.chat_message("user"):
            st.markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        with st.spinner("Pesquisando nos autos e gerando resposta..."):
            try:
                from langchain_google_genai import ChatGoogleGenerativeAI
                
                if not google_api_key:
                    st.error("Insira a Google API Key na barra lateral.")
                else:
                    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", google_api_key=google_api_key, temperature=0.3)
                    
                    # 1. RAG Retrieval: Busca trechos relevantes para a pergunta
                    retrieved_docs = st.session_state.retriever.invoke(prompt)
                    context_str = "\n\n".join([doc.page_content for doc in retrieved_docs])
                    
                    # 2. Montagem do Hist√≥rico (simplificado para Gemini)
                    chat_history = [
                        SystemMessage(content="Voc√™ √© um assistente jur√≠dico especializado. Responda de forma precisa, citando os documentos quando relevante."),
                    ]
                    
                    for msg in st.session_state.messages[:-1]:
                        if msg["role"] == "user":
                            chat_history.append(HumanMessage(content=msg["content"]))
                        else:
                            chat_history.append(AIMessage(content=msg["content"]))
                    
                    # 3. Adiciona a Pergunta Atual com Contexto Enriquecido (RAG)
                    rag_message_content = f"""
                    Informa√ß√µes Relevantes encontradas nos autos atrav√©s de busca vetorial:
                    {context_str}
                    
                    Pergunta do Usu√°rio:
                    {prompt}
                    """
                    chat_history.append(HumanMessage(content=rag_message_content))
                    
                    # 4. Invoke LLM
                    response = llm.invoke(chat_history)
                    
                    with st.chat_message("assistant"):
                        st.markdown(response.content)
                    
                    st.session_state.messages.append({"role": "assistant", "content": response.content})
                
            except Exception as e:
                st.error(f"Erro: {e}")
                st.expander("Detalhes do erro").text(traceback.format_exc())
