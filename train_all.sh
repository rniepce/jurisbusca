#!/bin/bash
set -e

# Ativa ambiente virtual (caso esteja rodando fora)
source ./venv/bin/activate || true

echo "ğŸ“‚ Verificando Dataset..."
if [ ! -f "data/train.jsonl" ]; then
    echo "âš ï¸  data/train.jsonl nÃ£o encontrado. Tentando extrair..."
    python extract_dataset.py
else
    echo "âœ… Dataset encontrado."
fi

echo "================================================"
echo "ğŸš€ INICIANDO FINE-TUNING EM SÃ‰RIE"
echo "================================================"

echo ""
echo "ğŸ§  [1/3] Treinando Mistral Nemo 12B..."
python -m mlx_lm.lora --config configs/mistral_nemo.yaml
echo "âœ… Mistral Nemo finalizado!"

echo ""
echo "ğŸ¦™ [2/3] Treinando Llama 3.1 8B..."
python -m mlx_lm.lora --config configs/llama3_1.yaml
echo "âœ… Llama 3.1 finalizado!"

echo ""
echo "ğŸ’ [3/3] Treinando Gemma 2 27B..."
echo "âš ï¸  Nota: Este modelo Ã© pesado. Se faltar memÃ³ria, reduza batch_size no config."
python -m mlx_lm.lora --config configs/gemma2_27b.yaml
echo "âœ… Gemma 2 finalizado!"

echo "================================================"
echo "ğŸ‰ TODOS OS TREINOS CONCLUÃDOS COM SUCESSO!"
echo "Os adaptadores (LoRA) estÃ£o salvos na pasta 'adapters/'"
